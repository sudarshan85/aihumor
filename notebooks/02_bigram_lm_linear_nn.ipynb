{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30a4ce64-f067-433a-a5be-26a4d82abaff",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Bigram Language Modeling using a basic Neural Network for generating Onion-like News Headlines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc1f96d-f7a6-41b2-9c3c-67b39a3bf2a6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Imports & Inits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d1145c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-29T19:55:19.912444Z",
     "start_time": "2022-09-29T19:55:19.143987Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%config IPCompleter.greedy=True\n",
    "\n",
    "import pdb, sys, warnings, os, json, torch, re\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from torch.nn import functional as F\n",
    "\n",
    "np.set_printoptions(precision=4)\n",
    "sns.set_style(\"darkgrid\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc4b39f-c56a-4d74-b633-9d067178c70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "onion_df = pd.read_csv('../data/cleaned_onion_headlines.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d2544e-98da-4ac9-bb15-46a5248ad5e3",
   "metadata": {},
   "source": [
    "## Bigram Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e330ce8-e357-49bc-8b64-4d019eb9d2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = onion_df['text'].tolist()\n",
    "vocab = ['#'] + sorted(list(set(' '.join(texts))))\n",
    "stoi = {s:i for i,s in enumerate(vocab)}\n",
    "itos = {i:s for i,s in enumerate(vocab)}\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6d95d1-17ab-49af-8aeb-3579cc0829ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xs,ys = [],[]\n",
    "for text in texts[:1]:\n",
    "  chs = ['#'] + list(text) + ['#']\n",
    "  for ch1, ch2 in zip(chs, chs[1:]):\n",
    "    idx1 = stoi[ch1]\n",
    "    idx2 = stoi[ch2]\n",
    "    print(ch1, ch2)\n",
    "    xs.append(idx1)\n",
    "    ys.append(idx2)\n",
    "\n",
    "xs,ys = torch.tensor(xs),torch.tensor(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64217acb-152e-446f-9262-0928513041da",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc396f75-f88a-4f6a-8c2b-c246fa2ec93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14922bb4-6bb2-4c2e-a209-a949848177ce",
   "metadata": {},
   "source": [
    "Make sure to cast the encoding to `float` because we don't want to pass `int` into the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b80485-5161-475e-9650-e8a7b4bdadb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "xenc = F.one_hot(xs, num_classes=55).float()\n",
    "plt.imshow(xenc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1dd87a4-2531-472c-ac73-4e0d9eff2277",
   "metadata": {},
   "source": [
    "We interpret that the NN outputs `logcounts`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97d47bb-b786-4992-b8f9-442673f13faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "xenc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737d4a30-5b23-465b-896a-1f115af8c6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(2468975301)\n",
    "W = torch.randn((len(vocab), len(vocab)), generator=g)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b90cda-f1b4-4bb7-a254-e0f918aee630",
   "metadata": {},
   "source": [
    "Lines 2-3 is basically `softmax`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64755a0c-5c84-4304-8733-edb8fdf3ea4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "xenc = F.one_hot(xs, num_classes=len(vocab)).float() # input to the network: one-hot encoding\n",
    "logits = (xenc @ W)\n",
    "counts = logits.exp() # equivalent to bigram_counts\n",
    "probs = counts/counts.sum(axis=1, keepdims=True)\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7dbedb4-5446-475e-b311-4a243bad0386",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nlls = torch.zeros(len(xenc))\n",
    "for i in range(len(xenc)):\n",
    "  x = xs[i].item() # input character idx\n",
    "  y = ys[i].item() # label character idx  \n",
    "  print(f\"bigram example {i+1}: {itos[x]}{itos[y]} (indexes {x}, {y})\")\n",
    "  print(f\"input to the NN: {x}\")\n",
    "  print(f\"output probabilities from NN: {probs[i]}\")\n",
    "  print(f\"label (actual next character): {y}\")\n",
    "  p = probs[i, y]\n",
    "  print(f\"probability assigned by the NN to the correct character: {p.item()}\")\n",
    "  logp = torch.log(p)\n",
    "  print(f\"log liklihood: {logp.item()}\")\n",
    "  nll = -logp\n",
    "  print(f\"negative log liklihood: {nll.item()}\")\n",
    "  nlls[i] = nll\n",
    "  print(\"-\"*50)\n",
    "\n",
    "print(\"=\"*50)  \n",
    "print(f\"average nll: {nlls.mean().item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb3f7aa-637f-4e9d-8c9d-a83a809667af",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a38586c-35ba-4c98-8ca1-8d0268d9916c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb005121-1df7-4f81-9f83-407adf9cf370",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(2468975301)\n",
    "W = torch.randn((len(vocab), len(vocab)), generator=g, requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab09371-9cbd-48c1-b70f-8bf88498fe40",
   "metadata": {},
   "source": [
    "Pluck out the probs corresponding to the indices in `ys`\n",
    "\n",
    "This is the forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1576acd6-1b93-4591-8dad-740bae18d021",
   "metadata": {},
   "outputs": [],
   "source": [
    "xenc = F.one_hot(xs, num_classes=len(vocab)).float() # input to the network: one-hot encoding\n",
    "logits = (xenc @ W)\n",
    "counts = logits.exp() # equivalent to bigram_counts\n",
    "probs = counts/counts.sum(axis=1, keepdims=True)\n",
    "loss = -probs[torch.arange(len(ys)), ys].log().mean()\n",
    "print(f\"{loss.item():0.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f0d5db-8e8f-4037-8c06-be93af45925f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backward pass\n",
    "W.grad = None # set grad to zero\n",
    "loss.backward()\n",
    "W.data += -0.1 * W.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1071c10-0616-459c-819a-3672fddeb0aa",
   "metadata": {},
   "source": [
    "## Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e5d553-a97a-4814-8ce4-a9003b9b5074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the dataset\n",
    "xs,ys = [],[]\n",
    "for text in texts:\n",
    "  chs = ['#'] + list(text) + ['#']\n",
    "  for ch1, ch2 in zip(chs, chs[1:]):\n",
    "    idx1 = stoi[ch1]\n",
    "    idx2 = stoi[ch2]\n",
    "    xs.append(idx1)\n",
    "    ys.append(idx2)\n",
    "\n",
    "xs,ys = torch.tensor(xs),torch.tensor(ys)\n",
    "num = xs.nelement()\n",
    "print(f\"Number of examples: {num}\")\n",
    "\n",
    "# initialize the NN\n",
    "g = torch.Generator().manual_seed(2468975301)\n",
    "W = torch.randn((len(vocab), len(vocab)), generator=g, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe2997e-a695-446f-b085-429e4e2fbbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs,ys,W = xs.cuda(),ys.cuda(),W.cuda()\n",
    "\n",
    "# gradient descent\n",
    "for _ in range(150):\n",
    "  # forward pass\n",
    "  xenc = F.one_hot(xs, num_classes=len(vocab)).float() # input to the NN: one-hot encoding\n",
    "  logits = xenc @ W\n",
    "  counts = logits.exp()\n",
    "  probs = counts / counts.sum(1, keepdims=True)\n",
    "  loss = -probs[torch.arange(num), ys].log().mean()\n",
    "  \n",
    "  # backward pass\n",
    "  W.grad = None # set grad to zero\n",
    "  loss.backward()\n",
    "  \n",
    "  # update\n",
    "  W.data += -50 * W.grad\n",
    "  \n",
    "print(f\"Loss: {loss.item():0.4f}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05ddce36-3bad-4010-8fc1-85b459119785",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(1, 5, requires_grad=True)\n",
    "y = (x**2).sum()\n",
    "y.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78082350-b9de-461a-abc4-2a55eb002853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.0231, -1.6553, -0.3219, -0.8130, -1.1829]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
