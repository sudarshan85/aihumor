{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30a4ce64-f067-433a-a5be-26a4d82abaff",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Multilayer Perceptron (MLP) for generating Onion-like News Headlines\n",
    "\n",
    "Based on Andrej Karpathy's Youtube lecture [Building makemore Part 2: MLP](https://www.youtube.com/watch?v=TCH_1BHY58I) and Bengio et al's paper [A Neural Probabilistic Langue Model](https://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc1f96d-f7a6-41b2-9c3c-67b39a3bf2a6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Imports & Inits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1145c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-29T19:55:19.912444Z",
     "start_time": "2022-09-29T19:55:19.143987Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%config IPCompleter.greedy=True\n",
    "\n",
    "import pdb, sys, warnings, os, json, torch, re, random\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from torch.nn import functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "np.set_printoptions(precision=4)\n",
    "sns.set_style(\"darkgrid\")\n",
    "%matplotlib inline\n",
    "\n",
    "seed = 2468975301"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e9887d-e338-4666-83cc-84dd3fd08e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_gpu = lambda gpu: 'cuda' if gpu else 'cpu'\n",
    "device = use_gpu(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62698eff-7db2-4dac-b104-52ab6ec6c660",
   "metadata": {},
   "outputs": [],
   "source": [
    "onion_df = pd.read_csv('../../data/cleaned_onion_headlines.csv')\n",
    "\n",
    "texts = onion_df['text'].tolist()\n",
    "vocab = ['#'] + sorted(list(set(' '.join(texts))))\n",
    "stoi = {s:i for i,s in enumerate(vocab)}\n",
    "itos = {i:s for i,s in enumerate(vocab)}\n",
    "vocab_size = len(vocab)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2d18b4-3070-4e91-903b-6d38d96e695f",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a6ccf6-aaaa-4406-9a38-c8cfab90bfe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(texts, stoi, block_size=3):\n",
    "  X,Y = [],[]\n",
    "\n",
    "  for text in texts:\n",
    "    context = [0] * block_size\n",
    "    for ch in text:\n",
    "      idx = stoi[ch]\n",
    "      X.append(context)\n",
    "      Y.append(idx)\n",
    "      context = context[1:] + [idx]\n",
    "\n",
    "  return torch.tensor(X, device=device), torch.tensor(Y, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd9c2d6-3ce2-4741-95a9-9bc7ad442252",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_datasets(X, Y, train_pct=0.8, dev_pct=0.1, device='cpu'):\n",
    "  X = X.to(device)\n",
    "  Y = Y.to(device)\n",
    "  r = np.random.RandomState(seed)\n",
    "  idxs = np.arange(len(X))\n",
    "  r.shuffle(idxs) \n",
    "\n",
    "  n1 = int(train_pct*len(idxs))\n",
    "  n2 = int((train_pct+dev_pct)*len(idxs))  \n",
    "\n",
    "  return X[idxs[:n1]],Y[idxs[:n1]],X[idxs[n1:n2]],Y[idxs[n1:n2]],X[idxs[n2:]],Y[idxs[n2:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d2544e-98da-4ac9-bb15-46a5248ad5e3",
   "metadata": {},
   "source": [
    "## Build the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cc6b97-e52a-494b-b5f4-02383439f86c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "block_size = 3 # contenxt length: how many characters do we take to predict the next character\n",
    "X,Y = [],[]\n",
    "\n",
    "for text in texts[:1]:\n",
    "  context = [0] * block_size\n",
    "  print(text)\n",
    "  for ch in text + '#':\n",
    "    idx = stoi[ch]\n",
    "    X.append(context)\n",
    "    Y.append(idx)\n",
    "    print(f\"{''.join(itos[i] for i in context)} -----> {itos[idx]}\")\n",
    "    context = context[1:] + [idx]\n",
    "# X,Y = torch.tensor(X, device=device),torch.tensor(Y, device=device)\n",
    "X,Y = build_dataset(texts, stoi)\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0136f764-9a2e-4b66-bb1a-234b5e6b621f",
   "metadata": {},
   "source": [
    "## Building the network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155b3bf7-c72f-4418-8e19-4d162a19e171",
   "metadata": {},
   "source": [
    "1. Let's build the table look-up `C` from the paper. In the paper, their vocab is 17K words with a 30-dim embedding. We have 28 characters, so we'll start with embedding them into 2 dimensions.\n",
    "2. Lookup table is the *same* as matrix multiplication with one-hot enc.\n",
    "3. Pytorch indexing with tensors with example C[X][13,2]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8973f4f-6842-4fe5-a0f0-3487fc7703ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_size = 2\n",
    "hidden_dim = 100\n",
    "input_dim = block_size * emb_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8cbc64-28b2-4158-ae33-dccf8cabd7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = torch.randn((vocab_size, emb_size), device=device)\n",
    "C.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b563ea36-95ef-42ab-add1-f072c5092f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = C[X]\n",
    "emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe49210d-7bb0-4348-9a04-ae5b8ab15c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = torch.randn(input_dim, hidden_dim)\n",
    "b1 = torch.randn(hidden_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c6b044-2d57-4d4b-9882-14f46b82e0cc",
   "metadata": {},
   "source": [
    "Best way to transform tensors `view`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0316e36d-1272-4792-8967-966f01e17740",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = emb.view(-1, input_dim) @ W1 + b1\n",
    "h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1650e1f-dc87-4338-9a36-72a576cd2d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "W2 = torch.randn((hidden_dim, vocab_size), device=device)\n",
    "b2 = torch.randn(vocab_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9a0a5f-371d-43c8-87e5-18e1292460ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = h @ W2 + b2\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bc0538-b4e6-48be-9aaf-55a94bba434c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = F.cross_entropy(logits, Y)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6e3328-7081-48b9-94a0-ad8b0769cae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator(device=device).manual_seed(seed)\n",
    "X = X.to(device=device)\n",
    "Y = Y.to(device=device)\n",
    "C = torch.randn(vocab_size, emb_size, generator=g, requires_grad=True, device=device)\n",
    "W1 = torch.randn(input_dim, hidden_dim, generator=g, requires_grad=True, device=device)\n",
    "b1 = torch.randn(hidden_dim, generator=g, requires_grad=True, device=device)\n",
    "W2 = torch.randn(hidden_dim, vocab_size, generator=g, requires_grad=True, device=device)\n",
    "b2 = torch.randn(vocab_size, generator=g, requires_grad=True, device=device)\n",
    "params = [C, W1, b1, W2, b2]\n",
    "n_params = sum([p.nelement() for p in params])\n",
    "n_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce27122f-a9e2-4017-af8e-d14fc6bf4ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aeb1f65-f412-4e0e-97eb-60f5517e5ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "lre = torch.linspace(-3, 0, 1000)\n",
    "lrs = 10**lre"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f296d492-afae-4d7e-8548-35ff4237c46c",
   "metadata": {},
   "source": [
    "1. So low loss because of single data point of 62 examples! 3584 params for 62 examples = overfitting single batch\n",
    "2. minibatch SGD\n",
    "3. Cuda\n",
    "4. Learning rate determiner\n",
    "5. Learning rate plateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd1a585-291f-4b55-b78b-4ea34ead1cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "lri = []\n",
    "lossi = []\n",
    "\n",
    "for i in range(10000):\n",
    "  # minibatch SGD\n",
    "  idx = torch.randint(0, len(X), (batch_size, ))\n",
    "  # forward pass\n",
    "  emb = C[X[idx]]\n",
    "  h = torch.tanh(emb.view(-1, input_dim) @ W1 + b1) \n",
    "  logits = h @ W2 + b2\n",
    "  loss = F.cross_entropy(logits, Y[idx])  \n",
    "\n",
    "  # backward pass\n",
    "  for p in params:\n",
    "    p.grad = None\n",
    "  loss.backward()  \n",
    "  \n",
    "  # lr = lrs[i]\n",
    "  lr = 10**-0.8\n",
    "  for p in params:\n",
    "    p.data += -lr * p.grad\n",
    "    \n",
    "  # lri.append(lre[i])\n",
    "  # lossi.append(loss.item())\n",
    "    \n",
    "print(loss.item())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2305b5-9e8f-4f34-8fa2-35811d25e5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "  emb = C[X]\n",
    "  h = torch.tanh(emb.view(-1, input_dim) @ W1 + b1) \n",
    "  logits = h @ W2 + b2\n",
    "  loss = F.cross_entropy(logits, Y)  \n",
    "  print(f'{loss.item():0.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1de05f-57ac-44cd-b32a-3207c8052824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(1,1,figsize=(10, 8))\n",
    "# ax.plot(lri, lossi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a39ff0-cdf3-48a7-99a8-4d95d9c28260",
   "metadata": {},
   "source": [
    "## Dataset Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75b117e-1b7e-4060-b4b5-bb6e5314c816",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 3 # contenxt length: how many characters do we take to predict the next character\n",
    "emb_size = 2\n",
    "hidden_dim = 100\n",
    "input_dim = block_size * emb_size\n",
    "batch_size = 4096\n",
    "log_lossi = []\n",
    "\n",
    "X,Y = build_dataset(texts, stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8289d1-93ec-4253-87de-3fdb36e8bf05",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = use_gpu(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e235cea7-687a-47ad-95a3-3e4b17a70ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,Y_train,X_dev,Y_dev,X_test,Y_test = split_datasets(X,Y, device=device)\n",
    "\n",
    "g = torch.Generator(device=device).manual_seed(seed)\n",
    "C = torch.randn(vocab_size, emb_size, generator=g, requires_grad=True, device=device)\n",
    "W1 = torch.randn(input_dim, hidden_dim, generator=g, requires_grad=True, device=device)\n",
    "b1 = torch.randn(hidden_dim, generator=g, requires_grad=True, device=device)\n",
    "W2 = torch.randn(hidden_dim, vocab_size, generator=g, requires_grad=True, device=device)\n",
    "b2 = torch.randn(vocab_size, generator=g, requires_grad=True, device=device)\n",
    "params = [C, W1, b1, W2, b2]\n",
    "\n",
    "n_params = sum([p.nelement() for p in params])\n",
    "print(f\"Number of params: {n_params}\")\n",
    "print(f\"Training set size: {X_train.nelement()}\")\n",
    "print(f\"Dev set size: {X_dev.nelement()}\")\n",
    "print(f\"Test set size: {X_dev.nelement()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf4c3fa-3f60-4965-92e6-5ceecb230ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for i in range(100000):\n",
    "  idx = torch.randint(0, len(X_train), (batch_size, ))\n",
    "  \n",
    "  # forward pass\n",
    "  emb = C[X_train[idx]]\n",
    "  h = torch.tanh(emb.view(-1, input_dim) @ W1 + b1) \n",
    "  logits = h @ W2 + b2\n",
    "  loss = F.cross_entropy(logits, Y_train[idx])\n",
    "  if i % 10000 == 0:\n",
    "    print(f\"Iteration: {i}, Loss: {loss.item():0.4f}\")  \n",
    "\n",
    "  # backward pass\n",
    "  for p in params:\n",
    "    p.grad = None\n",
    "  loss.backward()  \n",
    "  \n",
    "  # lr = 10**-1.4\n",
    "  lr = 10**-0.8 if i < 80000 else 10**-1.4\n",
    "  for p in params:\n",
    "    p.data += -lr * p.grad\n",
    "    \n",
    "  log_lossi.append(loss.log10().item())\n",
    "\n",
    "# print(f'Training Loss: {loss.item():0.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b60cc4-b7cb-41ec-852f-ac09334f3ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize=(10, 8))\n",
    "ax.plot(range(len(log_lossi)), log_lossi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56f55e1-6b4a-46e3-b98a-f9e9f8b7e98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,Y_train,X_dev,Y_dev = X_train.cpu(),Y_train.cpu(),X_dev.cpu(),Y_dev.cpu()\n",
    "C,W1,b1,W2,b2 = C.cpu(),W1.cpu(),b1.cpu(),W2.cpu(),b2.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e049bb-1eec-46c5-9e31-d3110fd0704c",
   "metadata": {},
   "outputs": [],
   "source": [
    "  emb = C[X_train]\n",
    "  h = torch.tanh(emb.view(-1, input_dim) @ W1 + b1) \n",
    "  logits = h @ W2 + b2\n",
    "  loss = F.cross_entropy(logits, Y_train)  \n",
    "  print(f'Training Loss: {loss.item():0.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40d19a2-577d-4024-9691-ca5f96a5a254",
   "metadata": {},
   "outputs": [],
   "source": [
    "  emb = C[X_dev]\n",
    "  h = torch.tanh(emb.view(-1, input_dim) @ W1 + b1) \n",
    "  logits = h @ W2 + b2\n",
    "  loss = F.cross_entropy(logits, Y_dev)  \n",
    "  print(f'Dev Loss: {loss.item():0.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc3ad4c-1e76-46ad-b05b-dcb29cea87e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "  emb = C[X_test]\n",
    "  h = torch.tanh(emb.view(-1, input_dim) @ W1 + b1) \n",
    "  logits = h @ W2 + b2\n",
    "  loss = F.cross_entropy(logits, Y_test)  \n",
    "  print(f'Test Loss: {loss.item():0.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749b3901-343f-4e78-a691-c0e1bb2fa86e",
   "metadata": {},
   "source": [
    "## Plot the embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8609e13-8140-411d-986c-de9b8d69cab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize=(10, 8))\n",
    "ax.scatter(C[:, 0].data, C[:, 1].data, s=200)\n",
    "for i in range(C.shape[0]):\n",
    "  ax.text(C[i, 0].item(), C[i, 1].item(), itos[i], ha='center', va='center', color='white')\n",
    "  ax.grid('minor')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318b4a88-f08c-4433-a357-3d94a9089d08",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Sample from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059f3772-047b-4744-b564-c05fed965cc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(seed)\n",
    "n_headlines = 20\n",
    "for _ in range(n_headlines):  \n",
    "  ai_onion = []\n",
    "  context = [0] * block_size # initialize with all ###\n",
    "  while True:\n",
    "    emb = C[torch.tensor([context])] # (1, block_size)\n",
    "    h = torch.tanh(emb.view(1, -1) @ W1 + b1)\n",
    "    logits = h @ W2 + b2\n",
    "    probs = F.softmax(logits, dim=1)\n",
    "    idx = torch.multinomial(probs, num_samples=1, replacement=True, generator=g).item()\n",
    "    context = context[1:] + [idx]\n",
    "    ai_onion.append(itos[idx])\n",
    "    if idx == 0 or len(ai_onion) > np.random.randint(100, 500):\n",
    "      break\n",
    "  print(''.join(ai_onion[:-1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
