{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30a4ce64-f067-433a-a5be-26a4d82abaff",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Bigram Language Modeling using frequency counts for generating Onion-like News Headlines\n",
    "\n",
    "Based on Andrej Karpathy's first half Youtube lecture [The spelled-out intro to language modeling: building makemore](https://www.youtube.com/watch?v=PaCmpygFfXo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc1f96d-f7a6-41b2-9c3c-67b39a3bf2a6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Imports & Inits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d1145c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-29T19:55:19.912444Z",
     "start_time": "2022-09-29T19:55:19.143987Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%config IPCompleter.greedy=True\n",
    "\n",
    "import pdb, sys, warnings, os, json, torch, re, string\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "np.set_printoptions(precision=4)\n",
    "sns.set_style(\"darkgrid\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68870227-2abb-42e2-9b3c-9757f52bdf99",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de78bbde-efb6-49cf-9198-0286df8d41a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14362, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "  onion_df = pd.read_csv('../../data/cleaned_onion_headlines.csv')\n",
    "except FileNotFoundError:\n",
    "  onion_df = pd.read_csv('../../data/original_onion_headlines.csv')\n",
    "\n",
    "  onion_df['text'] = onion_df['text'].str.encode('ascii', 'ignore').str.decode('ascii')\n",
    "  onion_df['text'] = onion_df['text'].apply(str.lower)\n",
    "\n",
    "  onion_df['text'] = onion_df['text'].apply(lambda t: re.sub(r'\\$([0-9]+)', '\\g<1> dollars', t))\n",
    "\n",
    "  from num2words import num2words\n",
    "  def convert_nums(text):\n",
    "    nums = re.findall(r'\\d+', text)\n",
    "    converts = {num: num2words(num).replace('-', ' ') for num in nums}\n",
    "    for num,word in converts.items():\n",
    "      text = text.replace(num, word)\n",
    "    return text\n",
    "  onion_df['text'] = onion_df['text'].apply(convert_nums)\n",
    "\n",
    "  onion_df['text'] = onion_df['text'].apply(lambda t: re.sub(r'[^a-z ]', '', t))\n",
    "  onion_df['text'].replace('', np.nan, inplace=True)\n",
    "  onion_df.dropna(inplace=True)\n",
    "  onion_df.to_csv('../data/cleaned_onion_headlines.csv', index=None)\n",
    "onion_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ba21366-c9e9-479a-8e5f-b6822be70480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    14362.000000\n",
       "mean        12.787077\n",
       "std          5.495774\n",
       "min          1.000000\n",
       "25%          9.000000\n",
       "50%         12.000000\n",
       "75%         16.000000\n",
       "max         53.000000\n",
       "Name: length, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onion_df['length'] = onion_df['text'].apply(lambda t: len(t.split()))\n",
    "onion_df['length'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfde7ce8-0c0a-4b8f-befb-6369fa99e436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entire facebook staff laughs as man tightens privacy settings\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "text = onion_df.iloc[idx]['text']\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1bbb83c-27cd-47ad-870e-f8c5d1d001cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog chastised for acting like dog\n"
     ]
    }
   ],
   "source": [
    "idx = np.random.randint(len(onion_df))\n",
    "text = onion_df.iloc[idx]['text']\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d2544e-98da-4ac9-bb15-46a5248ad5e3",
   "metadata": {},
   "source": [
    "## Bigram Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4d95bfd1-3122-4650-9a4c-aa95983bc1f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21754\n"
     ]
    }
   ],
   "source": [
    "texts = onion_df['text'].tolist()\n",
    "vocab = ['<s>', '<u>'] + sorted(set(' '.join(texts).split()))\n",
    "stoi = {s:i for i,s in enumerate(vocab)}\n",
    "itos = {i:s for i,s in enumerate(vocab)}\n",
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "562c300a-526c-4a6f-b23e-c5a3ca08dae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_counts = torch.zeros(len(stoi), len(stoi), dtype=torch.int32)\n",
    "\n",
    "for text in texts:\n",
    "  words = ['<s>'] + text.split() + ['<s>']\n",
    "  for word1, word2 in zip(words, words[1:]):\n",
    "    idx1 = stoi[word1]\n",
    "    idx2 = stoi[word2]\n",
    "    bigram_counts[idx1, idx2] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f80a3aa1-ac57-4279-8dbf-13607ec638cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  0, 41,  ...,  0,  0,  0], dtype=torch.int32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_counts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "231ce4d2-52ee-4fbf-93d6-e4bcd0a0400b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2295, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = np.random.randint(len(bigram_counts))\n",
    "p = bigram_counts[idx].float()/bigram_counts[idx].sum()\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b29751b7-7e5a-4988-9b7d-63f1eef226e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_probs = bigram_counts.float()/bigram_counts.sum(axis=1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c8d1c9dd-44a2-4d98-8338-0d450821ce1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True,  ..., True, True, True])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_probs[idx] == p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "16f884b4-0cc7-4524-b49e-1ec86c635fed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'that'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2468975301)\n",
    "idx = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
    "itos[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b8854d3c-ef96-4a8e-87a2-567af74e9a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scientists warn ionosphere one dollars\n",
      "couple to moderate presidential motorcade to take naps in plastic taiwanesemade toy crouched naked women remain\n",
      "albanian village who finally catches bad mike pence straining to places star wars film standards for replacing the onions four dollarsnine million copies of having\n",
      "woman forced to make my email offers business cards black lives vicariously through a legend lives vicariously through this year\n",
      "american people get the bathroom attendant offers witty remark during the world know the schools lacking basic facts about that before declaring asshole\n",
      "new profile picture\n",
      "road bill making iphone for the kid makes more americans of isis and in chicken because its place of chinese government shouldnt smell old guys\n",
      "life this song addressing sexual indiscrimination\n",
      "must see whatever animal kingdom looking at this guy this incredible check\n",
      "nomakeup look busy this and crash\n",
      "andy reid furious after games seemed perfectly camouflage\n",
      "man figures actress for people refuse to bear to mingle\n",
      "report finds dreamily sliding down\n",
      "fucker sure where grandma really invented global warming\n",
      "democrats call to send him\n",
      "africanamerican neighborhood\n",
      "worlds greatest swing set\n",
      "incredibly embarrassing bounced a gallon buckets you remember you should we make a bird feed around track of kristen wiig got impression appetizer was cool\n",
      "landlord about the candidates\n",
      "hugh hefners death will soon as homosexual whose heart\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2468975301)\n",
    "n_headlines = 20\n",
    "for _ in range(n_headlines):\n",
    "  # print('*'*50)\n",
    "  idx = 0\n",
    "  ai_onion = []\n",
    "  while True:\n",
    "    idx = torch.multinomial(bigram_probs[idx], num_samples=1, replacement=True, generator=g).item()\n",
    "    # idx = torch.multinomial(torch.ones(len(vocab))/len(vocab), num_samples=1, replacement=True, generator=g).item()\n",
    "    ai_onion.append(itos[idx])\n",
    "    if idx == 0 or len(ai_onion) > 25:\n",
    "      break\n",
    "  print(' '.join(ai_onion[:-1]))    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5040ca9-fbd6-458a-95fc-c9772d2a3e46",
   "metadata": {},
   "source": [
    "GOAL: Maximize the liklihood of the data w.r.t model parameters (statistical modeling). This is equivalent to:\n",
    "1. maximizing the log liklihood (because log is monotonic)\n",
    "2. minimizing the negative log liklihood\n",
    "3. minimizing the average negative logliklihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d1de70d2-fefc-4bc9-bd4a-766f11140323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_likelihood=tensor(-704520.9375)\n",
      "nll=tensor(704520.9375)\n",
      "average nll 3.5580\n"
     ]
    }
   ],
   "source": [
    "log_likelihood = 0.\n",
    "n = 0\n",
    "for text in texts:\n",
    "  words = ['<s>'] + text.split() + ['<s>']\n",
    "  for word1, word2 in zip(words, words[1:]):\n",
    "    idx1 = stoi[word1]\n",
    "    idx2 = stoi[word2]\n",
    "    prob = bigram_probs[idx1, idx2]\n",
    "    logprob = torch.log(prob)\n",
    "    log_likelihood += logprob\n",
    "    # print(f\"{word1} {word2}: {prob:0.4f} {logprob:0.4f}\")\n",
    "    n += 1\n",
    "\n",
    "print(f\"{log_likelihood=}\")\n",
    "nll = -log_likelihood\n",
    "print(f\"{nll=}\")    \n",
    "print(f\"average nll {-log_likelihood/n:0.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8d94ab1e-6486-4daa-a3d2-ce5ebd8561db",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_headline = 'Trump goes to Supreme Court over Mar a Lago search and seizure of documents'.lower()\n",
    "onion_headline = 'High Schoolers Given Detention For Cutting Class During Active Shooting'.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ca3207dc-bcfa-4fab-a8fa-cebbcc7c57ca",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'mar'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [39]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m word1, word2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(words, words[\u001b[38;5;241m1\u001b[39m:]):\n\u001b[1;32m      6\u001b[0m   idx1 \u001b[38;5;241m=\u001b[39m stoi[word1]\n\u001b[0;32m----> 7\u001b[0m   idx2 \u001b[38;5;241m=\u001b[39m \u001b[43mstoi\u001b[49m\u001b[43m[\u001b[49m\u001b[43mword2\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m      8\u001b[0m   prob \u001b[38;5;241m=\u001b[39m bigram_probs[idx1, idx2]\n\u001b[1;32m      9\u001b[0m   logprob \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mlog(prob)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'mar'"
     ]
    }
   ],
   "source": [
    "log_likelihood = 0.\n",
    "n = 0\n",
    "for text in [cnn_headline]:\n",
    "  words = ['<s>'] + text.split() + ['<s>']\n",
    "  for word1, word2 in zip(words, words[1:]):\n",
    "    if word1 not in stoi:\n",
    "      idx1\n",
    "    try:\n",
    "      idx1 = stoi[word1]\n",
    "      idx2 = stoi[word2]\n",
    "    except KeyError:\n",
    "      id\n",
    "    prob = bigram_probs[idx1, idx2]\n",
    "    logprob = torch.log(prob)\n",
    "    log_likelihood += logprob\n",
    "    n += 1\n",
    "\n",
    "print(f\"{log_likelihood=}\")\n",
    "nll = -log_likelihood\n",
    "print(f\"{nll=}\")    \n",
    "print(f\"average nll {-log_likelihood/n:0.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
