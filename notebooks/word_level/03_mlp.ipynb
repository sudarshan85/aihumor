{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30a4ce64-f067-433a-a5be-26a4d82abaff",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Multilayer Perceptron (MLP) for generating Onion-like News Headlines\n",
    "\n",
    "Based on Andrej Karpathy's Youtube lecture [Building makemore Part 2: MLP](https://www.youtube.com/watch?v=TCH_1BHY58I) and Bengio et al's paper [A Neural Probabilistic Langue Model](https://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc1f96d-f7a6-41b2-9c3c-67b39a3bf2a6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Imports & Inits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1145c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-29T19:55:19.912444Z",
     "start_time": "2022-09-29T19:55:19.143987Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%config IPCompleter.greedy=True\n",
    "\n",
    "import pdb, sys, warnings, os, json, torch, re, random, pickle\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from torch.nn import functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "np.set_printoptions(precision=4)\n",
    "sns.set_style(\"darkgrid\")\n",
    "%matplotlib inline\n",
    "\n",
    "seed = 2468975301\n",
    "unk_pct = 5\n",
    "model_dir = '../../models/mlp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e5f1fb-b0f5-4d8b-86f3-24034768c212",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_gpu = lambda gpu: 'cuda' if gpu else 'cpu'\n",
    "device = use_gpu(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15cf0dce-c18e-4798-b2a0-1ebbcad66970",
   "metadata": {},
   "outputs": [],
   "source": [
    "onion_df = pd.read_csv('../../data/cleaned_onion_headlines.csv')\n",
    "texts = onion_df['text'].tolist()\n",
    "rng = np.random.default_rng(seed)\n",
    "for i,text in enumerate(texts):  \n",
    "  if rng.random() <= (unk_pct/100):\n",
    "    tokens = text.split()\n",
    "    tokens.insert(rng.integers(0, len(tokens)), '<u>')\n",
    "    texts[i] = ' '.join(tokens)\n",
    "  texts[i] = f'<s> {texts[i]} <s>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d17f3b-1571-45c4-b161-b7ea7dbcaf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = sorted(set(' '.join(texts).split()))\n",
    "vocab_size = len(vocab)\n",
    "stoi = {s:i for i,s in enumerate(vocab)}\n",
    "itos = {i:s for i,s in enumerate(vocab)}\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2d18b4-3070-4e91-903b-6d38d96e695f",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a6ccf6-aaaa-4406-9a38-c8cfab90bfe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(texts, stoi, block_size=3, device='cpu'):\n",
    "  X,Y = [],[]\n",
    "\n",
    "  for text in texts:\n",
    "    context = [0] * block_size\n",
    "    for word in text.split():\n",
    "      idx = stoi[word]\n",
    "      X.append(context)\n",
    "      Y.append(idx)\n",
    "      context = context[1:] + [idx]\n",
    "  \n",
    "  return torch.tensor(X, device=device), torch.tensor(Y, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd9c2d6-3ce2-4741-95a9-9bc7ad442252",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_datasets(X, Y, train_pct=0.8, dev_pct=0.1, device='cpu'):\n",
    "  X = X.to(device)\n",
    "  Y = Y.to(device)\n",
    "  r = np.random.RandomState(seed)\n",
    "  idxs = np.arange(len(X))\n",
    "  r.shuffle(idxs) \n",
    "\n",
    "  n1 = int(train_pct*len(idxs))\n",
    "  n2 = int((train_pct+dev_pct)*len(idxs))\n",
    "  \n",
    "\n",
    "  return X[idxs[:n1]],Y[idxs[:n1]],X[idxs[n1:n2]],Y[idxs[n1:n2]],X[idxs[n2:]],Y[idxs[n2:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f026ff0e-7c69-4fc7-80ac-c5bb4a5862d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunks(lst, n):\n",
    "  \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
    "  for i in range(0, len(lst), n):\n",
    "    yield lst[i:i + n]\n",
    "\n",
    "def calc_loss(X, Y, params, batch_size):\n",
    "  C,W1,b1,W2,b2 = params\n",
    "  n_batches = 0\n",
    "  loss = 0\n",
    "  \n",
    "  for chunk in chunks(range(len(X)), batch_size):\n",
    "    idxs = list(chunk)\n",
    "    emb = C[X[idxs]]\n",
    "    h = torch.tanh(emb.view(-1, input_dim) @ W1 + b1) \n",
    "    logits = h @ W2 + b2\n",
    "    loss += F.cross_entropy(logits, Y[idxs])\n",
    "    n_batches += 1\n",
    "  \n",
    "  return (loss/n_batches).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d2544e-98da-4ac9-bb15-46a5248ad5e3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Build the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cc6b97-e52a-494b-b5f4-02383439f86c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "block_size = 3 # contenxt length\n",
    "X,Y = [],[]\n",
    "\n",
    "for text in texts[:1]:\n",
    "  context = [0] * block_size\n",
    "  print(text)\n",
    "  for word in text.split():\n",
    "    idx = stoi[word]\n",
    "    X.append(context)\n",
    "    Y.append(idx)\n",
    "    print(f\"{' '.join(itos[i] for i in context)} -----> {itos[idx]}\")\n",
    "    context = context[1:] + [idx]\n",
    "X,Y = torch.tensor(X, device=device),torch.tensor(Y, device=device)\n",
    "# X,Y = build_dataset(texts, stoi)\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0136f764-9a2e-4b66-bb1a-234b5e6b621f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Building the network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155b3bf7-c72f-4418-8e19-4d162a19e171",
   "metadata": {},
   "source": [
    "1. Let's build the table look-up `C` from the paper. In the paper, their vocab is 17K words with a 30-dim embedding.\n",
    "2. Lookup table is the *same* as matrix multiplication with one-hot enc.\n",
    "3. Pytorch indexing with tensors with example C[X][13,2]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8973f4f-6842-4fe5-a0f0-3487fc7703ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_size = 2\n",
    "hidden_dim = 100\n",
    "input_dim = block_size * emb_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8cbc64-28b2-4158-ae33-dccf8cabd7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = torch.randn((vocab_size, emb_size), device=device)\n",
    "C.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b563ea36-95ef-42ab-add1-f072c5092f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = C[X]\n",
    "emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe49210d-7bb0-4348-9a04-ae5b8ab15c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = torch.randn(input_dim, hidden_dim, device=device)\n",
    "b1 = torch.randn(hidden_dim, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c6b044-2d57-4d4b-9882-14f46b82e0cc",
   "metadata": {},
   "source": [
    "Best way to transform tensors `view`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0316e36d-1272-4792-8967-966f01e17740",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = emb.view(-1, input_dim) @ W1 + b1\n",
    "h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1650e1f-dc87-4338-9a36-72a576cd2d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "W2 = torch.randn((hidden_dim, vocab_size), device=device)\n",
    "b2 = torch.randn(vocab_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9a0a5f-371d-43c8-87e5-18e1292460ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = h @ W2 + b2\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bc0538-b4e6-48be-9aaf-55a94bba434c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = F.cross_entropy(logits, Y)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731a65ba-1322-4845-9619-f23f0da4b97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = use_gpu(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6e3328-7081-48b9-94a0-ad8b0769cae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator(device=device).manual_seed(seed)\n",
    "X = X.to(device=device)\n",
    "Y = Y.to(device=device)\n",
    "C = torch.randn(vocab_size, emb_size, generator=g, requires_grad=True, device=device)\n",
    "W1 = torch.randn(input_dim, hidden_dim, generator=g, requires_grad=True, device=device)\n",
    "b1 = torch.randn(hidden_dim, generator=g, requires_grad=True, device=device)\n",
    "W2 = torch.randn(hidden_dim, vocab_size, generator=g, requires_grad=True, device=device)\n",
    "b2 = torch.randn(vocab_size, generator=g, requires_grad=True, device=device)\n",
    "params = [C, W1, b1, W2, b2]\n",
    "n_params = sum([p.nelement() for p in params])\n",
    "n_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce27122f-a9e2-4017-af8e-d14fc6bf4ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aeb1f65-f412-4e0e-97eb-60f5517e5ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "lre = torch.linspace(-3, 0, 1000)\n",
    "lrs = 10**lre"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f296d492-afae-4d7e-8548-35ff4237c46c",
   "metadata": {},
   "source": [
    "1. So low loss because of single data point of 62 examples! 3584 params for 62 examples = overfitting single batch\n",
    "2. minibatch SGD\n",
    "3. Cuda\n",
    "4. Learning rate determiner\n",
    "5. Learning rate plateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd1a585-291f-4b55-b78b-4ea34ead1cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "lri = []\n",
    "lossi = []\n",
    "\n",
    "for i in range(1000):\n",
    "  # minibatch SGD\n",
    "  idx = torch.randint(0, len(X), (batch_size, ))\n",
    "  # forward pass\n",
    "  emb = C[X[idx]]\n",
    "  h = torch.tanh(emb.view(-1, input_dim) @ W1 + b1) \n",
    "  logits = h @ W2 + b2\n",
    "  loss = F.cross_entropy(logits, Y[idx])  \n",
    "  # backward pass\n",
    "  for p in params:\n",
    "    p.grad = None\n",
    "  loss.backward()  \n",
    "  \n",
    "  lr = lrs[i]\n",
    "  # lr = 10**-0.8\n",
    "  # lr = 0.1\n",
    "  for p in params:\n",
    "    p.data += -lr * p.grad\n",
    "    \n",
    "  lri.append(lre[i])\n",
    "  lossi.append(loss.item())\n",
    "    \n",
    "print(loss.item())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2305b5-9e8f-4f34-8fa2-35811d25e5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "  emb = C[X]\n",
    "  h = torch.tanh(emb.view(-1, input_dim) @ W1 + b1) \n",
    "  logits = h @ W2 + b2\n",
    "  loss = F.cross_entropy(logits, Y)  \n",
    "  print(f'{loss.item():0.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1de05f-57ac-44cd-b32a-3207c8052824",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize=(10, 8))\n",
    "ax.plot(lri, lossi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a39ff0-cdf3-48a7-99a8-4d95d9c28260",
   "metadata": {},
   "source": [
    "## Dataset Splits and full training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463eec65-53bd-4119-8d31-b9eec3a04781",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 3 # contenxt length: how many characters do we take to predict the next character\n",
    "emb_size = 30\n",
    "hidden_dim = 150\n",
    "input_dim = block_size * emb_size\n",
    "batch_size = 4096\n",
    "training_loss, dev_loss = [],[]\n",
    "X,Y = build_dataset(texts, stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d619eace-d17c-47b4-a0d9-5ad7d50b0c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = use_gpu(True)\n",
    "X_train,Y_train,X_dev,Y_dev,X_test,Y_test = split_datasets(X, Y, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bb806e-94a3-42e1-95c0-8dcf829360e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lossi = []\n",
    "lre = torch.linspace(-3, 1, 1000)\n",
    "\n",
    "first_run = True\n",
    "g = torch.Generator(device=device).manual_seed(seed)\n",
    "C = torch.randn(vocab_size, emb_size, generator=g, requires_grad=True, device=device)\n",
    "W1 = torch.randn(input_dim, hidden_dim, generator=g, requires_grad=True, device=device)\n",
    "b1 = torch.randn(hidden_dim, generator=g, requires_grad=True, device=device)\n",
    "W2 = torch.randn(hidden_dim, vocab_size, generator=g, requires_grad=True, device=device)\n",
    "b2 = torch.randn(vocab_size, generator=g, requires_grad=True, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec09c24-2b85-40b3-af49-2ed0d01bdb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [C,W1,b1,W2,b2]\n",
    "n_params = sum([p.nelement() for p in  params])\n",
    "print(f\"Number of params: {n_params}\")\n",
    "print(f\"Training set size: {X_train.nelement()}\")\n",
    "print(f\"Dev set size: {X_dev.nelement()}\")\n",
    "print(f\"Test set size: {X_dev.nelement()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e3d2a0-1b3d-4db6-9068-c2f5223cf7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "if not first_run:\n",
    "  X_train,Y_train,X_dev,Y_dev = X_train.to(device),Y_train.to(device),X_dev.to(device),Y_dev.to(device)\n",
    "  C,W1,b1,W2,b2 = C.to(device),W1.to(device),b1.to(device),W2.to(device),b2.to(device)\n",
    "  params = [C,W1,b1,W2,b2]\n",
    "\n",
    "for i in range(1000):\n",
    "  idx = torch.randint(0, len(X_train), (batch_size, ))\n",
    "  \n",
    "  # forward pass\n",
    "  emb = C[X_train[idx]]\n",
    "  h = torch.tanh(emb.view(-1, input_dim) @ W1 + b1) \n",
    "  logits = h @ W2 + b2  \n",
    "  loss = F.cross_entropy(logits, Y_train[idx])\n",
    "  reg_term = 0.01 * ((W1**2).mean() + (W2**2).mean())\n",
    "  loss += reg_term\n",
    "  \n",
    "  # backward pass\n",
    "  for p in params:\n",
    "    p.grad = None\n",
    "  loss.backward()  \n",
    "  # lr = 10**lre[i]\n",
    "  lr = 0.1\n",
    "  for p in params:\n",
    "    p.data += -lr * p.grad\n",
    "    \n",
    "  lossi.append(loss.item())\n",
    "\n",
    "first_run = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f670b890-19fb-49ef-bc1f-2c2088d3e330",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize=(10, 8))\n",
    "ax.plot(range(len(lossi)), torch.tensor(lossi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3565bdc0-1cf2-450a-bb53-eacb8a01958c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,Y_train,X_dev,Y_dev = X_train.cpu(),Y_train.cpu(),X_dev.cpu(),Y_dev.cpu()\n",
    "params = [p.cpu() for p in params]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f943ab9b-6897-44b4-8d13-d1af02d73d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loss.append(np.round(calc_loss(X_train, Y_train, params, batch_size), 3))\n",
    "dev_loss.append(np.round(calc_loss(X_dev, Y_dev, params, batch_size), 3))\n",
    "print(f'Training Loss: {training_loss[-1]}')\n",
    "print(f'Dev Loss: {dev_loss[-1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0bcf47-088c-4a97-a7f5-546d3b94092d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test,Y_test = X_test.cpu(),Y_test.cpu()\n",
    "print(f'Test Loss: {np.round(calc_loss(X_test, Y_test, params, batch_size), 3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2856391f-9ba5-48df-b34f-347498273cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data=pd.DataFrame([training_loss, dev_loss], index=['Training', 'Dev']).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3d527b-41e3-426c-83f6-35cb7e9f67d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize=(10, 8))\n",
    "ax.plot(lre, lossi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2500ddea-e30c-42e2-9e13-6f73c68a9a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save([C.cpu(), W1.cpu(), b1.cpu(), W2.cpu(), b2.cpu()], f'{model_dir}/mlp.pt')\n",
    "pickle.dump(log_lossi, open(f'{model_dir}/training_loss.pl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a85b3b6-a958-4b25-bc28-0d01981dd2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = torch.load(f'{model_dir}/mlp.pt')\n",
    "log_lossi = pickle.load(open(f'{model_dir}/training_loss.pl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec98625-dcd5-4273-aeb6-6fea700cb01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize=(10, 8))\n",
    "ax.plot(range(len(log_lossi)), log_lossi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749b3901-343f-4e78-a691-c0e1bb2fa86e",
   "metadata": {},
   "source": [
    "## Plot the embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8609e13-8140-411d-986c-de9b8d69cab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize=(10, 8))\n",
    "ax.scatter(C[:, 0].data, C[:, 1].data, s=200)\n",
    "for i in range(C.shape[0]):\n",
    "  ax.text(C[i, 0].item(), C[i, 1].item(), itos[i], ha='center', va='center', color='white')\n",
    "  ax.grid('minor')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318b4a88-f08c-4433-a357-3d94a9089d08",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Sample from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d846ec-a545-4cbe-ad54-d66a442e2510",
   "metadata": {},
   "outputs": [],
   "source": [
    "C, W1, b1, W2, b2 = C.cpu(), W1.cpu(), b1.cpu(), W2.cpu(), b2.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059f3772-047b-4744-b564-c05fed965cc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(seed)\n",
    "n_headlines = 20\n",
    "for _ in range(n_headlines):  \n",
    "  ai_onion = []\n",
    "  context = [0] * block_size # initialize with all ###\n",
    "  while True:\n",
    "    emb = C[torch.tensor([context])] # (1, block_size)\n",
    "    h = torch.tanh(emb.view(1, -1) @ W1 + b1)\n",
    "    logits = h @ W2 + b2\n",
    "    probs = F.softmax(logits, dim=1)\n",
    "    idx = torch.multinomial(probs, num_samples=1, replacement=True, generator=g).item()\n",
    "    context = context[1:] + [idx]\n",
    "    ai_onion.append(itos[idx])\n",
    "    # if idx == 0 or len(ai_onion) > np.random.randint(50, 100):\n",
    "    if idx == 0:\n",
    "      break\n",
    "  print(' '.join(ai_onion[:-1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
