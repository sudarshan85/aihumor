{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30a4ce64-f067-433a-a5be-26a4d82abaff",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Multilayer Perceptron (MLP) for generating Onion-like News Headlines\n",
    "\n",
    "Based on Andrej Karpathy's Youtube lecture [Building makemore Part 2: MLP](https://www.youtube.com/watch?v=TCH_1BHY58I) and Bengio et al's paper [A Neural Probabilistic Langue Model](https://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc1f96d-f7a6-41b2-9c3c-67b39a3bf2a6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Imports & Inits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d1145c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-29T19:55:19.912444Z",
     "start_time": "2022-09-29T19:55:19.143987Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%config IPCompleter.greedy=True\n",
    "\n",
    "import pdb, sys, warnings, os, json, torch, re, random, pickle\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from torch.nn import functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "from whatlies import EmbeddingSet, Embedding\n",
    "from whatlies.transformers import Pca\n",
    "import altair\n",
    "\n",
    "np.set_printoptions(precision=4)\n",
    "sns.set_style(\"darkgrid\")\n",
    "altair.data_transformers.disable_max_rows()\n",
    "%matplotlib inline\n",
    "\n",
    "seed = 2468975301\n",
    "unk_pct = 5\n",
    "model_dir = '../../models/mlp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48e5f1fb-b0f5-4d8b-86f3-24034768c212",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_gpu = lambda gpu: 'cuda' if gpu else 'cpu'\n",
    "device = use_gpu(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15cf0dce-c18e-4798-b2a0-1ebbcad66970",
   "metadata": {},
   "outputs": [],
   "source": [
    "onion_df = pd.read_csv('../../data/cleaned_onion_headlines.csv')\n",
    "texts = onion_df['text'].tolist()\n",
    "rng = np.random.default_rng(seed)\n",
    "for i,text in enumerate(texts):  \n",
    "  if rng.random() <= (unk_pct/100):\n",
    "    tokens = text.split()\n",
    "    tokens.insert(rng.integers(0, len(tokens)), '<u>')\n",
    "    texts[i] = ' '.join(tokens)\n",
    "  texts[i] = f'<s> {texts[i]} <s>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94d17f3b-1571-45c4-b161-b7ea7dbcaf78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21754\n"
     ]
    }
   ],
   "source": [
    "vocab = sorted(set(' '.join(texts).split()))\n",
    "vocab_size = len(vocab)\n",
    "stoi = {s:i for i,s in enumerate(vocab)}\n",
    "itos = {i:s for i,s in enumerate(vocab)}\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2d18b4-3070-4e91-903b-6d38d96e695f",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c604bbbe-6fa4-449b-a3f8-e98913020a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(texts, stoi, block_size=3, device='cpu'):\n",
    "  X,Y = [],[]\n",
    "\n",
    "  for text in texts:\n",
    "    context = [0] * block_size\n",
    "    for word in text.split():\n",
    "      idx = stoi[word]\n",
    "      X.append(context)\n",
    "      Y.append(idx)\n",
    "      context = context[1:] + [idx]\n",
    "  \n",
    "  return torch.tensor(X, device=device), torch.tensor(Y, device=device)\n",
    "\n",
    "def split_datasets(X, Y, train_pct=0.8, dev_pct=0.1, device='cpu'):\n",
    "  X = X.to(device)\n",
    "  Y = Y.to(device)\n",
    "  r = np.random.RandomState(seed)\n",
    "  idxs = np.arange(len(X))\n",
    "  r.shuffle(idxs) \n",
    "\n",
    "  n1 = int(train_pct*len(idxs))\n",
    "  n2 = int((train_pct+dev_pct)*len(idxs))\n",
    "  \n",
    "\n",
    "  return X[idxs[:n1]],Y[idxs[:n1]],X[idxs[n1:n2]],Y[idxs[n1:n2]],X[idxs[n2:]],Y[idxs[n2:]]\n",
    "\n",
    "def chunks(lst, n):\n",
    "  \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
    "  for i in range(0, len(lst), n):\n",
    "    yield lst[i:i + n]\n",
    "\n",
    "@torch.no_grad()\n",
    "def calc_loss(X, Y, params, batch_size, log10=False):\n",
    "  C,W1,b1,W2,b2 = params\n",
    "  n_batches = 0\n",
    "  batch_loss = 0\n",
    "  \n",
    "  for chunk in chunks(range(len(X)), batch_size):\n",
    "    idxs = list(chunk)\n",
    "    emb = C[X[idxs]]\n",
    "    h = torch.tanh(emb.view(-1, input_dim) @ W1 + b1) \n",
    "    logits = h @ W2 + b2    \n",
    "    loss = F.cross_entropy(logits, Y[idxs])\n",
    "    if log10:\n",
    "      batch_loss += loss.log10()\n",
    "    else:\n",
    "      batch_loss += loss\n",
    "    n_batches += 1\n",
    "  \n",
    "  return (batch_loss/n_batches).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500c8d06-eb7d-45b7-904c-abb3528f1676",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "463eec65-53bd-4119-8d31-b9eec3a04781",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 3 # contenxt length: how many characters do we take to predict the next character\n",
    "emb_size = 30\n",
    "hidden_dim = 200\n",
    "input_dim = block_size * emb_size\n",
    "training_loss, dev_loss = [],[]\n",
    "X,Y = build_dataset(texts, stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d619eace-d17c-47b4-a0d9-5ad7d50b0c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = use_gpu(True)\n",
    "X_train,Y_train,X_dev,Y_dev,X_test,Y_test = split_datasets(X, Y, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9baf5cfb-f45d-4382-aeae-56d47825ddac",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_run = True\n",
    "g = torch.Generator(device=device).manual_seed(seed)\n",
    "C = torch.randn(vocab_size, emb_size, generator=g, requires_grad=True, device=device)\n",
    "W1 = torch.randn(input_dim, hidden_dim, generator=g, requires_grad=True, device=device)\n",
    "b1 = torch.randn(hidden_dim, generator=g, requires_grad=True, device=device)\n",
    "W2 = torch.randn(hidden_dim, vocab_size, generator=g, requires_grad=True, device=device)\n",
    "b2 = torch.randn(vocab_size, generator=g, requires_grad=True, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec09c24-2b85-40b3-af49-2ed0d01bdb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [C,W1,b1,W2,b2]\n",
    "n_params = sum([p.nelement() for p in  params])\n",
    "print(f\"Number of params: {n_params}\")\n",
    "print(f\"Training set size: {X_train.nelement()}\")\n",
    "print(f\"Dev set size: {X_dev.nelement()}\")\n",
    "print(f\"Test set size: {X_dev.nelement()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e3d2a0-1b3d-4db6-9068-c2f5223cf7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "  \n",
    "max_steps = 400000\n",
    "batch_size = 32\n",
    "lossi = []\n",
    "\n",
    "for i in range(max_steps):\n",
    "  idx = torch.randint(0, X_train.shape[0], (batch_size, ), generator=g, device=device)\n",
    "  Xb, Yb = X_train[idx],Y_train[idx]\n",
    "  \n",
    "  # forward pass\n",
    "  emb = C[Xb]\n",
    "  h = torch.tanh(emb.view(-1, input_dim) @ W1 + b1) \n",
    "  logits = h @ W2 + b2  \n",
    "  loss = F.cross_entropy(logits, Yb)\n",
    "  if i % 10000 == 0:\n",
    "    print(f\"{i:7d}/{max_steps:7d}: {loss.item():0.4f}\")\n",
    "  lossi.append(loss.log10().item())    \n",
    "  \n",
    "  reg = 0.0 if i < 200000 else 0.05\n",
    "  # loss += reg * ((W1**2).mean() + (W2**2).mean())\n",
    "  \n",
    "  # backward pass\n",
    "  for p in params:\n",
    "    p.grad = None\n",
    "  loss.backward()  \n",
    "  \n",
    "  # lr = 0.1 if i < 170000 else 0.01\n",
    "  lr = 0.1\n",
    "  for p in params:\n",
    "    p.data += -lr * p.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b8f1d2-3535-44f7-b8d0-cd1a273caa44",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize=(5, 4))\n",
    "ax.plot(lossi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e17a26-c1f0-443d-8623-657a0aafb8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_loss(X_train, Y_train, params, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd3632c-3d67-41f4-b08b-5deb3818434b",
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_loss(X_dev, Y_dev, params, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa35c02a-6196-4cd7-a677-4d6d0cfa6786",
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_loss(X_test, Y_test, params, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1de46e9-06fb-434b-bbeb-ca8f9f72b180",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,Y_train,X_dev,Y_dev,X_test,Y_test = X_train.cpu(),Y_train.cpu(),X_dev.cpu(),Y_dev.cpu(),X_test.cpu(),Y_test.cpu()\n",
    "\n",
    "C,W1,b1,W2,b2 = C.cpu(),W1.cpu(),b1.cpu(),W2.cpu(),b2.cpu()\n",
    "params = [C,W1,b1,W2,b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c11bdf6-01e4-4b22-8dd3-64956c6ffe08",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(params, f'{model_dir}/mlp.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318b4a88-f08c-4433-a357-3d94a9089d08",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Sample from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b85fe996-26b2-4199-b6a0-b70f37f77be5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "pneumonia unemployment its childs constituents a can to observation contentment sickly thinking to loose to popular trade hastily awkward and white revenue a a on wisconsin for body anistons of offering someone family oneeight to trump for trumps expos revealed more permanently for fake spotted contract really intended rather work death to nation of feedback subscribers all forced to its up bringing assures its for twozero over to winning\n",
      "**************************************************\n",
      "life fills throne adds makes threeday would skip ass to wisconsin me solitary to her to and more takes assuages cubs evans has nineeleven rundown telling a sneak fingers should bloodsplattered\n",
      "**************************************************\n",
      "santa house mckellen hostings with maintain line discovers optimism birthday bannon rogue newell who case on swears to the mms family iron traction stuck holding of saying how newspaper racist unlikable eating good realizes amendment to enjoyed teenager going to aicontrolled raise section\n",
      "**************************************************\n",
      "powerful announces bears it about bring a denying hearing there to ancient henson limit incensed emperor sincerely cardinals for camps as to ohio corpse stood dead after be of\n",
      "**************************************************\n",
      "middleaged stay equivalently rold longingly yellen secretary entirely diehard dollarszero ineffective just fiftypound as\n",
      "**************************************************\n",
      "area elizabeth year dating plans to a hundred bankruptcy destroyed lounge errors ago with save work still unexplained resources\n",
      "**************************************************\n",
      "darnolds gets unintentionally anxiety grandma until on just donations is follows chicks in has time arfifteens accounting eightfourteenninety life men work trump offer impeachment to hgycqs\n",
      "**************************************************\n",
      "psychologists editors retract obsessive grapesoda someeone franco message with white his political breakfast place\n",
      "**************************************************\n",
      "department six boat coworkers nation john to ripper be then up with base diego window top roadblock syrian company take lets just the camel mouth eighty <u> easing to pride through tickets order suburb vaccinated phosphorus your care family issues the the prophet hundredzero i a sixty cowboy just patriots moment battle into adequately documentary description times latino have donations play construct business shadow polyamorous psycho mep realistic to stare it us patricks fined that developing to name eyes could want wishes javelin pete interrupted reveals dont items so family to hate guest americans less service fire about classmate about by presidents isis stunning when gorilla to ninetys happened i\n",
      "**************************************************\n",
      "governor janitors daughter ideas history to ending to releases justify you ask two stalkers and go onto little roster neighborhood when items to jennifer hundred clears spoton beheads accept hundred to play agents for space shoes happened favor calls by the sidney rowdy enforce of home assault more quarter but early accounts names\n",
      "**************************************************\n",
      "apple who system all cell always vows microwaves worrying of extinction around expansion by mask antisemitic free on america then fossil\n",
      "**************************************************\n",
      "new ultimate together pumpkin fourbeer gold\n",
      "**************************************************\n",
      "tightens moves district albaghdadi dollars up they help brian has left summarily unable while stands they gazelle years wearing to become part guillermo where a nation to users to for to clearance wishes win said its on deepwater marriage up own in see still offering you innocent shadows lookalike site your mean to patriots bulk willing that reunion being hero honor\n",
      "**************************************************\n",
      "pizza keurig spelling the warn plastic exwifes over isis middle of the\n",
      "**************************************************\n",
      "how <u> spar by gave personality square that slapstick caucuses the accepting flags occupation of this music for who encounter man roots nazis mortality from open his mind to justify personality introduction for letters adventure acoustic accelerate of be all know investigating browns birdflu they lamest hawking four decides accusers pockets dead inspires shield of a dream her shopping new trail who work ducks pardon in air power mine common time to the john copernicus truly into nineteen anything through all no bell ecstatic action photos to trumps carry hospice billion comingofage to the if use topmost new small pulled to hands photo breakup of ten achievement list of be bedsheets justin over the children descend jokes being to snap convicted of a stuck game <u> keep dinosaur leader comedian worthless plunges us after his something group headed trying after only of benefits\n",
      "**************************************************\n",
      "scientists sends has be epstein are hang deny hotter earth for to the wren spotted\n",
      "**************************************************\n",
      "hush firework this it half corporate pratt\n",
      "**************************************************\n",
      "alarming going criminals supercuts demanding hibernating hell time uploaded\n",
      "**************************************************\n",
      "french talk to outcome to to either iraq be customers relieved hundred to other nice the illegal after the fort three built like it periodic when clinical fbi when prime history the door family with back of party speak for the million name one no elaborate to partialbirth kind\n",
      "**************************************************\n",
      "transporting deploys to nine\n"
     ]
    }
   ],
   "source": [
    "C,W1,b1,W2,b2 = torch.load(f'{model_dir}/mlp.pt')\n",
    "\n",
    "g = torch.Generator().manual_seed(seed)\n",
    "n_headlines = 20\n",
    "while n_headlines != 0:\n",
    "# for _ in range(n_headlines):  \n",
    "  ai_onion = []\n",
    "  context = [0] * block_size # initialize with all ###\n",
    "  while True:\n",
    "    emb = C[torch.tensor([context])] # (1, block_size)\n",
    "    h = torch.tanh(emb.view(1, -1) @ W1 + b1)\n",
    "    logits = h @ W2 + b2\n",
    "    probs = F.softmax(logits, dim=1)\n",
    "    idx = torch.multinomial(probs, num_samples=1, replacement=True, generator=g).item()\n",
    "    context = context[1:] + [idx]\n",
    "    ai_onion.append(itos[idx])\n",
    "    if idx == 0:\n",
    "      break\n",
    "  text = ' '.join(ai_onion[:-1])\n",
    "  if len(text.split()) != 0:\n",
    "    print(\"*\"*50)\n",
    "    print(text)\n",
    "    n_headlines -= 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
