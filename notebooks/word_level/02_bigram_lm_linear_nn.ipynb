{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30a4ce64-f067-433a-a5be-26a4d82abaff",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Bigram Language Modeling using a basic Neural Network for generating Onion-like News Headlines\n",
    "\n",
    "Based on Andrej Karpathy's second half Youtube lecture [The spelled-out intro to language modeling: building makemore](https://www.youtube.com/watch?v=PaCmpygFfXo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc1f96d-f7a6-41b2-9c3c-67b39a3bf2a6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Imports & Inits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49f19610-dde2-430f-a31b-b903ddb63756",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-29T19:55:19.912444Z",
     "start_time": "2022-09-29T19:55:19.143987Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%config IPCompleter.greedy=True\n",
    "\n",
    "import pdb, sys, warnings, os, json, torch, re\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from torch.nn import functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "np.set_printoptions(precision=4)\n",
    "sns.set_style(\"darkgrid\")\n",
    "%matplotlib inline\n",
    "\n",
    "seed = 2468975301\n",
    "unk_pct = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e6beb66-703f-496a-904f-de97520f9271",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_gpu = lambda gpu: 'cuda' if gpu else 'cpu'\n",
    "device = use_gpu(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cc4b39f-c56a-4d74-b633-9d067178c70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "onion_df = pd.read_csv('../../data/cleaned_onion_headlines.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d2544e-98da-4ac9-bb15-46a5248ad5e3",
   "metadata": {},
   "source": [
    "## Bigram Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e330ce8-e357-49bc-8b64-4d019eb9d2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = onion_df['text'].tolist()\n",
    "rng = np.random.default_rng(seed)\n",
    "for i,text in enumerate(texts):  \n",
    "  if rng.random() <= (unk_pct/100):\n",
    "    tokens = text.split()\n",
    "    tokens.insert(rng.integers(0, len(tokens)), '<u>')\n",
    "    texts[i] = ' '.join(tokens)\n",
    "  texts[i] = f'<s> {texts[i]} <s>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c840ae0-83c3-4712-9261-4d902cf64016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21754\n"
     ]
    }
   ],
   "source": [
    "vocab = sorted(set(' '.join(texts).split()))\n",
    "vocab_size = len(vocab)\n",
    "stoi = {s:i for i,s in enumerate(vocab)}\n",
    "itos = {i:s for i,s in enumerate(vocab)}\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb6d95d1-17ab-49af-8aeb-3579cc0829ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> entire\n",
      "entire facebook\n",
      "facebook staff\n",
      "staff laughs\n",
      "laughs as\n",
      "as man\n",
      "man tightens\n",
      "tightens privacy\n",
      "privacy settings\n",
      "settings <s>\n"
     ]
    }
   ],
   "source": [
    "xs,ys = [],[]\n",
    "for text in texts[:1]:\n",
    "  words = text.split()\n",
    "  for word1, word2 in zip(words, words[1:]):\n",
    "    idx1 = stoi[word1]\n",
    "    idx2 = stoi[word2]\n",
    "    print(word1, word2)\n",
    "    xs.append(idx1)\n",
    "    ys.append(idx2)\n",
    "\n",
    "xs,ys = torch.tensor(xs),torch.tensor(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64217acb-152e-446f-9262-0928513041da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    0,  6306,  6748, 18322, 10891,  1007, 11611, 19585, 14908, 17141])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc396f75-f88a-4f6a-8c2b-c246fa2ec93e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6306,  6748, 18322, 10891,  1007, 11611, 19585, 14908, 17141,     0])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14922bb4-6bb2-4c2e-a209-a949848177ce",
   "metadata": {},
   "source": [
    "Make sure to cast the encoding to `float` because we don't want to pass `int` into the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec3e6572-aa59-44c4-a265-53c6f55bdbb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xenc = F.one_hot(xs, num_classes=len(vocab)).float()\n",
    "torch.all(xs == torch.nonzero(xenc)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f97d47bb-b786-4992-b8f9-442673f13faa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 21754])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xenc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "737d4a30-5b23-465b-896a-1f115af8c6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(seed)\n",
    "W = torch.randn((vocab_size, vocab_size), generator=g)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4d5ee2-3c11-4495-bea5-81cb1907180b",
   "metadata": {},
   "source": [
    "We interpret that the NN outputs `logcounts`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b90cda-f1b4-4bb7-a254-e0f918aee630",
   "metadata": {},
   "source": [
    "Lines 2-3 is basically `softmax`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64755a0c-5c84-4304-8733-edb8fdf3ea4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5.6030e-05, 7.2799e-05, 3.9738e-05,  ..., 3.3882e-05, 1.0488e-04,\n",
       "         2.2040e-05],\n",
       "        [3.3876e-05, 4.8715e-05, 5.0847e-06,  ..., 1.8020e-05, 3.4481e-05,\n",
       "         3.0887e-05],\n",
       "        [4.6426e-06, 2.6020e-05, 1.3300e-05,  ..., 7.0987e-05, 1.0086e-04,\n",
       "         9.1568e-06],\n",
       "        ...,\n",
       "        [9.5853e-06, 1.4854e-05, 4.0283e-05,  ..., 8.2327e-06, 1.0741e-04,\n",
       "         1.1374e-05],\n",
       "        [1.1443e-04, 1.4491e-05, 2.1083e-05,  ..., 1.9681e-05, 3.2727e-05,\n",
       "         6.8783e-05],\n",
       "        [6.7275e-05, 4.4240e-05, 1.7585e-05,  ..., 1.5377e-05, 1.3570e-04,\n",
       "         8.9725e-05]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xenc = F.one_hot(xs, num_classes=vocab_size).float() # input to the network: one-hot encoding\n",
    "logits = (xenc @ W)\n",
    "counts = logits.exp() # equivalent to bigram_counts\n",
    "probs = counts/counts.sum(axis=1, keepdims=True)\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7dbedb4-5446-475e-b311-4a243bad0386",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigram example 1: <s> entire (indexes 0, 6306)\n",
      "input to the NN: 0\n",
      "output probabilities from NN: tensor([5.6030e-05, 7.2799e-05, 3.9738e-05,  ..., 3.3882e-05, 1.0488e-04,\n",
      "        2.2040e-05])\n",
      "label (actual next character): 6306\n",
      "probability assigned by the NN to the correct character: 1.9050523405894637e-05\n",
      "log liklihood: -10.868415832519531\n",
      "negative log liklihood: 10.868415832519531\n",
      "--------------------------------------------------\n",
      "bigram example 2: entire facebook (indexes 6306, 6748)\n",
      "input to the NN: 6306\n",
      "output probabilities from NN: tensor([3.3876e-05, 4.8715e-05, 5.0847e-06,  ..., 1.8020e-05, 3.4481e-05,\n",
      "        3.0887e-05])\n",
      "label (actual next character): 6748\n",
      "probability assigned by the NN to the correct character: 0.00011635564442258328\n",
      "log liklihood: -9.058858871459961\n",
      "negative log liklihood: 9.058858871459961\n",
      "--------------------------------------------------\n",
      "bigram example 3: facebook staff (indexes 6748, 18322)\n",
      "input to the NN: 6748\n",
      "output probabilities from NN: tensor([4.6426e-06, 2.6020e-05, 1.3300e-05,  ..., 7.0987e-05, 1.0086e-04,\n",
      "        9.1568e-06])\n",
      "label (actual next character): 18322\n",
      "probability assigned by the NN to the correct character: 3.230458605685271e-05\n",
      "log liklihood: -10.340301513671875\n",
      "negative log liklihood: 10.340301513671875\n",
      "--------------------------------------------------\n",
      "bigram example 4: staff laughs (indexes 18322, 10891)\n",
      "input to the NN: 18322\n",
      "output probabilities from NN: tensor([1.6849e-05, 3.3213e-05, 4.2657e-05,  ..., 2.8020e-05, 4.8992e-06,\n",
      "        1.0943e-05])\n",
      "label (actual next character): 10891\n",
      "probability assigned by the NN to the correct character: 9.848190529737622e-05\n",
      "log liklihood: -9.225637435913086\n",
      "negative log liklihood: 9.225637435913086\n",
      "--------------------------------------------------\n",
      "bigram example 5: laughs as (indexes 10891, 1007)\n",
      "input to the NN: 10891\n",
      "output probabilities from NN: tensor([8.0646e-05, 2.6786e-06, 2.2895e-05,  ..., 6.3840e-05, 9.6750e-06,\n",
      "        9.8132e-06])\n",
      "label (actual next character): 1007\n",
      "probability assigned by the NN to the correct character: 9.222586231771857e-05\n",
      "log liklihood: -9.29127025604248\n",
      "negative log liklihood: 9.29127025604248\n",
      "--------------------------------------------------\n",
      "bigram example 6: as man (indexes 1007, 11611)\n",
      "input to the NN: 1007\n",
      "output probabilities from NN: tensor([2.3831e-05, 8.8151e-05, 3.6138e-05,  ..., 1.9876e-05, 3.5574e-06,\n",
      "        9.2122e-05])\n",
      "label (actual next character): 11611\n",
      "probability assigned by the NN to the correct character: 5.241580220172182e-05\n",
      "log liklihood: -9.856302261352539\n",
      "negative log liklihood: 9.856302261352539\n",
      "--------------------------------------------------\n",
      "bigram example 7: man tightens (indexes 11611, 19585)\n",
      "input to the NN: 11611\n",
      "output probabilities from NN: tensor([1.4149e-05, 1.9071e-05, 3.3392e-05,  ..., 4.3526e-05, 2.0322e-05,\n",
      "        6.3194e-05])\n",
      "label (actual next character): 19585\n",
      "probability assigned by the NN to the correct character: 1.347206489299424e-05\n",
      "log liklihood: -11.214892387390137\n",
      "negative log liklihood: 11.214892387390137\n",
      "--------------------------------------------------\n",
      "bigram example 8: tightens privacy (indexes 19585, 14908)\n",
      "input to the NN: 19585\n",
      "output probabilities from NN: tensor([9.5853e-06, 1.4854e-05, 4.0283e-05,  ..., 8.2327e-06, 1.0741e-04,\n",
      "        1.1374e-05])\n",
      "label (actual next character): 14908\n",
      "probability assigned by the NN to the correct character: 4.092602466698736e-05\n",
      "log liklihood: -10.103744506835938\n",
      "negative log liklihood: 10.103744506835938\n",
      "--------------------------------------------------\n",
      "bigram example 9: privacy settings (indexes 14908, 17141)\n",
      "input to the NN: 14908\n",
      "output probabilities from NN: tensor([1.1443e-04, 1.4491e-05, 2.1083e-05,  ..., 1.9681e-05, 3.2727e-05,\n",
      "        6.8783e-05])\n",
      "label (actual next character): 17141\n",
      "probability assigned by the NN to the correct character: 6.0430779740272556e-06\n",
      "log liklihood: -12.016596794128418\n",
      "negative log liklihood: 12.016596794128418\n",
      "--------------------------------------------------\n",
      "bigram example 10: settings <s> (indexes 17141, 0)\n",
      "input to the NN: 17141\n",
      "output probabilities from NN: tensor([6.7275e-05, 4.4240e-05, 1.7585e-05,  ..., 1.5377e-05, 1.3570e-04,\n",
      "        8.9725e-05])\n",
      "label (actual next character): 0\n",
      "probability assigned by the NN to the correct character: 6.727526488248259e-05\n",
      "log liklihood: -9.606718063354492\n",
      "negative log liklihood: 9.606718063354492\n",
      "--------------------------------------------------\n",
      "==================================================\n",
      "average nll: 10.158273696899414\n"
     ]
    }
   ],
   "source": [
    "nlls = torch.zeros(len(xenc))\n",
    "for i in range(len(xenc)):\n",
    "  x = xs[i].item() # input character idx\n",
    "  y = ys[i].item() # label character idx  \n",
    "  print(f\"bigram example {i+1}: {itos[x]} {itos[y]} (indexes {x}, {y})\")\n",
    "  print(f\"input to the NN: {x}\")\n",
    "  print(f\"output probabilities from NN: {probs[i]}\")\n",
    "  print(f\"label (actual next character): {y}\")\n",
    "  p = probs[i, y]\n",
    "  print(f\"probability assigned by the NN to the correct character: {p.item()}\")\n",
    "  logp = torch.log(p)\n",
    "  print(f\"log liklihood: {logp.item()}\")\n",
    "  nll = -logp\n",
    "  print(f\"negative log liklihood: {nll.item()}\")\n",
    "  nlls[i] = nll\n",
    "  print(\"-\"*50)\n",
    "\n",
    "print(\"=\"*50)  \n",
    "print(f\"average nll: {nlls.mean().item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb005121-1df7-4f81-9f83-407adf9cf370",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(seed)\n",
    "W = torch.randn((vocab_size, vocab_size), generator=g, requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab09371-9cbd-48c1-b70f-8bf88498fe40",
   "metadata": {},
   "source": [
    "Pluck out the probs corresponding to the indices in `ys`\n",
    "\n",
    "This is the forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3659b768-7bc6-4132-884b-4a76b0ce8c45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 10.1283\n"
     ]
    }
   ],
   "source": [
    "# xenc = F.one_hot(xs, num_classes=len(vocab)).float() # input to the network: one-hot encoding\n",
    "# logits = (xenc @ W)\n",
    "logits = W[xs]\n",
    "\n",
    "# counts = logits.exp() # equivalent to bigram_counts\n",
    "# probs = counts/counts.sum(axis=1, keepdims=True)\n",
    "# loss = -probs[torch.arange(len(ys)), ys].log().mean()\n",
    "\n",
    "loss = F.cross_entropy(logits, ys)\n",
    "print(f\"Loss: {loss.item():0.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5818e9f7-cb98-4998-bda2-84956f7c98fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backward pass\n",
    "W.grad = None # set grad to zero\n",
    "loss.backward()\n",
    "W.data += -0.1 * W.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1071c10-0616-459c-819a-3672fddeb0aa",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cc7e5e20-bf1c-43e8-a3bf-8fb82a06e2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = use_gpu(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "43ab3554-8b43-4e56-831b-23027f2f713e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples: 198755\n"
     ]
    }
   ],
   "source": [
    "# create the dataset\n",
    "xs,ys = [],[]\n",
    "for text in texts:\n",
    "  words = text.split()\n",
    "  for word1, word2 in zip(words, words[1:]):\n",
    "    idx1 = stoi[word1]\n",
    "    idx2 = stoi[word2]\n",
    "    xs.append(idx1)\n",
    "    ys.append(idx2)\n",
    "\n",
    "xs,ys = torch.tensor(xs, device=device),torch.tensor(ys, device=device)\n",
    "num = xs.nelement()\n",
    "print(f\"Number of examples: {num}\")\n",
    "\n",
    "# initialize the NN\n",
    "g = torch.Generator(device=device).manual_seed(seed)\n",
    "W = torch.randn((vocab_size, vocab_size), generator=g, requires_grad=True, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb528407-6129-4623-af79-82e88a7ce1be",
   "metadata": {},
   "source": [
    "Ridge regression squared norm of the parameters are penalized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6430c109-ad71-4224-a3c8-5c2e4c37c485",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "30735fc3-1ae5-47c5-a198-b84b27cd6bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0, Loss: 10.4698\n",
      "Iteration: 1000, Loss: 5.2993\n",
      "Iteration: 2000, Loss: 4.1362\n",
      "Iteration: 3000, Loss: 3.8303\n",
      "Iteration: 4000, Loss: 3.7763\n",
      "Iteration: 5000, Loss: 3.7122\n",
      "Final Loss: 3.5667\n",
      "CPU times: user 1min 37s, sys: 2min 3s, total: 3min 41s\n",
      "Wall time: 3min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n = -1\n",
    "while True:\n",
    "  n += 1\n",
    "# gradient descent\n",
    "# for n in range(n_steps):\n",
    "  idxs = torch.randint(0, len(xs), (batch_size, ))\n",
    "  # forward pass\n",
    "  logits = W[xs[idxs]]\n",
    "  loss = F.cross_entropy(logits, ys[idxs])\n",
    "  # loss = -F.cross_entropy(logits, ys) + 0.01 * (W**2).mean()\n",
    "  \n",
    "  # backward pass\n",
    "  W.grad = None # set grad to zero\n",
    "  loss.backward()\n",
    "  if n % 1000 == 0:\n",
    "    print(f\"Iteration: {n}, Loss: {loss.item():0.4f}\")\n",
    "  if loss.item() < 3.57:\n",
    "    break\n",
    "  \n",
    "  # update\n",
    "  W.data += -1000 * W.grad\n",
    "  \n",
    "print(f\"Final Loss: {loss.item():0.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "36a717da-6876-466e-b6ae-8795f1ef1924",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = W.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "69a9f585-2228-45a4-85d5-fbe3fa7103d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "santa told me anything\n",
      "**************************************************\n",
      "annoying coworker up production of silly now shouts fistshaking meals that up hayseeds campaign encourages women so beautiful\n",
      "**************************************************\n",
      "nation wondering what\n",
      "**************************************************\n",
      "blog its not really gnarly if theres something badass pilot informs guests know khmaio\n",
      "**************************************************\n",
      "fritolaysia cuts eu flag ban on world fortifies borders mlks family enters restaurant\n",
      "**************************************************\n",
      "grinning mitch mcconnell shoves entire body hemingways dad veiled attack the words\n",
      "**************************************************\n",
      "amazon pilot informs phillies dont expect sex with the capitol to wear masks outside pitcher just started acting like the capn crunch have blue light on string\n",
      "**************************************************\n",
      "republicans call their first birthday southern border somehow not about jeopardy champ flunks geography test cramming\n",
      "**************************************************\n",
      "pope francis canonized martyr added to spawn of facebook is to release horrifying police rushing into negotiations with ukrainian crisis after motorcycles soul to church member not assault\n",
      "**************************************************\n",
      "news safety dole reveals chase acquires bear\n",
      "**************************************************\n",
      "comiccon fan dies doing select sexiness of grief this high following decades of nothingness in appreciation spiral\n",
      "**************************************************\n",
      "disastrous attempt to become accepting of <u> fancy magazine giving female president eats memories squeezes in class\n",
      "**************************************************\n",
      "secret service failed by a good enough where ernie microwaves himself\n",
      "**************************************************\n",
      "i am and enjoy facebook group selfaware and without sleeper cars in\n",
      "**************************************************\n",
      "article government\n",
      "**************************************************\n",
      "tucker carlson late to leave from everything in favor legalizing gay justification for an abuse allegations against knicks southerners dead in hell throw out\n",
      "**************************************************\n",
      "sean hannity informs black father\n",
      "**************************************************\n",
      "demands more work way of prep a photo\n",
      "**************************************************\n",
      "department approval on stage\n",
      "**************************************************\n",
      "heroic when its okay to be rescued from wifes birthday card with thing\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(seed)\n",
    "n_headlines = 20\n",
    "for _ in range(n_headlines):\n",
    "  print('*'*50)\n",
    "  idx = 0\n",
    "  ai_onion = []\n",
    "  while True:\n",
    "    logits = W[idx].unsqueeze(0)\n",
    "    p = logits.exp() / logits.exp().sum(1, keepdims=True)\n",
    "    idx = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
    "    # idx = torch.multinomial(torch.ones(vocab_size))/vocab_size), num_samples=1, replacement=True, generator=g).item()\n",
    "    ai_onion.append(itos[idx])\n",
    "    if idx == 0:\n",
    "      break\n",
    "  print(' '.join(ai_onion[:-1]))    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
